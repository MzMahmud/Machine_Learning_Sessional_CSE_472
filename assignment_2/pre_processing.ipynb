{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "# nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "# nltk.download('stopwords')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# nltk.download('wordnet')\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = \"\"\"sees ran run <p><a href=\"http://forums.wpcentral.com/radar/188319.htm\" rel=\"nofollow\">This forum 123 thread</a> mentions that all 1st gen devices could do that, and Dave Blake confirms that all Mango devices do support that.</p>\n",
    "\n",
    "<p><a href=\"http://www.microsoft.com/southafrica/windowsphone/handsets.html\" rel=\"nofollow\">This page from Microsoft</a> has three 1st gen devices that mention A2DP support. I guess throwing a device name together with <code>A2DP</code> and <code>specifications</code> could help confirm if your device does, but as far as I can see all devices do support this.</p>\"\"\"\n",
    "\n",
    "def get_pre_processed(text):\n",
    "#     print(\"\\n----RAW----\\n\",text)\n",
    "    \n",
    "    # remove html tags\n",
    "    text = BeautifulSoup(text).text\n",
    "#     print(\"\\n\\n----html tags removed----\\n\",text)\n",
    "    \n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "#     print(\"\\n===After Lowercase:===\\n\", text)\n",
    "    \n",
    "    # Removing Numbers\n",
    "    text = re.sub(r'[-+]?\\d+\\b', '', text)\n",
    "#     print(\"\\n===After Removing Numbers:===\\n\", text)\n",
    "\n",
    "    # Remove punctuations\n",
    "    text = text.translate((str.maketrans('','',string.punctuation)))\n",
    "#     print(\"\\n===After Removing Punctuations:===\\n\", text)\n",
    "    \n",
    "    #Tokenize\n",
    "    text = word_tokenize(text)\n",
    "#     print(\"\\n===After Tokenizing:===\\n\", text)\n",
    "    \n",
    "    #Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = [word for word in text if not word in stop_words]\n",
    "#     print(\"\\n===After Stopword Removal:===\\n\", text)\n",
    "    \n",
    "    #Lemmatize tokens\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = [lemmatizer.lemmatize(word) for word in text]\n",
    "#     print(\"\\n===After Lemmatization:===\\n\", text)\n",
    "    \n",
    "    stemmer= PorterStemmer()\n",
    "    text = [stemmer.stem(word) for word in text]\n",
    "#     print(\"\\n===After Stemming:===\\n\", text)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "# print(\"\\n===Before Pre Processing:===\\n\",test_text)\n",
    "# test_text = get_pre_processed(test_text)\n",
    "# # print(\"\\n===After Pre Processing:===\\n\",test_text)\n",
    "# print(\"\\n===After Pre Processing:===\\n\",\" \".join(test_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_train_validation_test(DATA_DIR,topics,n_train,n_validation,n_test):\n",
    "    train = open(\"train.in\",'w',encoding='utf16')\n",
    "    validation = open(\"validation.in\",'w',encoding='utf16')\n",
    "    test = open(\"test.in\",'w',encoding='utf16')\n",
    "    \n",
    "    for topic in topics:\n",
    "        xml_file = os.path.join(DATA_DIR,f\"{topic}.xml\")\n",
    "        file = open(xml_file,'rb')\n",
    "        content = file.read()\n",
    "        soup = BeautifulSoup(content,'xml')\n",
    "\n",
    "        num = 1\n",
    "        for items in soup.findAll(\"row\"):\n",
    "            body = items.attrs['Body']\n",
    "            if len(body) == 0:\n",
    "                continue\n",
    "                # print(\"empty\",items)\n",
    "            \n",
    "            text = get_pre_processed(body)\n",
    "            text.append(topic)\n",
    "            doc = \" \".join(text)\n",
    "            if num <= n_train:\n",
    "                # train.write(f\"------{items.attrs['Id']}------\\n\")\n",
    "                print(doc,file=train)\n",
    "            elif n_train < num and num <= (n_train + n_validation):\n",
    "                # validation.write(f\"------{items.attrs['Id']}------\\n\")\n",
    "                print(doc,file=validation)\n",
    "            elif (n_train + n_validation) < num and num <= (n_train + n_validation + n_test):\n",
    "                # test.write(f\"------{items.attrs['Id']}------\\n\")\n",
    "                print(doc,file=test)\n",
    "            else:\n",
    "                break\n",
    "            num += 1\n",
    "        file.close()\n",
    "        \n",
    "    train.close()\n",
    "    validation.close()\n",
    "    test.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilove\\Documents\\ml_offline_2\\Data\\Training\n",
      "C:\\Users\\ilove\\Documents\\ml_offline_2\\Data\\topics.txt\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "DATA_DIR = os.path.join(os.path.join(os.getcwd(),\"Data\"),\"Training\") \n",
    "print(DATA_DIR)\n",
    "\n",
    "topics_txt = os.path.join(os.path.join(os.getcwd(),\"Data\"),\"topics.txt\")\n",
    "print(topics_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Coffee', 'Arduino', 'Windows_Phone']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the topics' name\n",
    "with open(topics_txt, 'r') as f:\n",
    "    topics = [topic.strip() for topic in f.readlines()]    \n",
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store_train_validation_test(os.getcwd(),['Sample','Sample2'],5,2,5)\n",
    "store_train_validation_test(DATA_DIR,topics,500,100,500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
